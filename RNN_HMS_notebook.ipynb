{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Load your preprocessed training data\n",
        "dataset= pd.read_csv('train.csv')\n",
        "df_train = dataset.drop_duplicates()\n",
        "df_train= dataset.iloc[:, [0,3] + list(range(-6, 0))]\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "# Select relevant columns\n",
        "selected_columns_train = ['spectrogram_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
        "selected_data_train = df_train[selected_columns_train]\n",
        "\n",
        "selected_columns_test = ['spectrogram_id', 'eeg_id', 'patient_id']\n",
        "selected_data_test = df_test[selected_columns_test]\n",
        "\n",
        "# Separate X_train and y_train\n",
        "X_train = selected_data_train[['spectrogram_id']]\n",
        "y_train = selected_data_train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler_X = StandardScaler()\n",
        "X_train_standardized = scaler_X.fit_transform(X_train)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_train_standardized = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# Reshape the data for LSTM input\n",
        "X_train_standardized_reshaped = X_train_standardized.reshape((X_train_standardized.shape[0], X_train_standardized.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train_standardized_reshaped.shape[1], 1)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_train_standardized.shape[1], activation='softmax'))  # Use softmax activation for probability distribution\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_standardized_reshaped, np.argmax(y_train_standardized, axis=1), epochs=10, batch_size=32)\n",
        "\n",
        "# Load test data\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Assuming 'spectrogram_id' is the relevant column for X_test\n",
        "X_test = test_data[['spectrogram_id']]\n",
        "\n",
        "# Standardize X_test using the same scaler_X\n",
        "X_test_standardized = scaler_X.transform(X_test)\n",
        "\n",
        "# Reshape the data for LSTM input\n",
        "X_test_standardized_reshaped = X_test_standardized.reshape((X_test_standardized.shape[0], X_test_standardized.shape[1], 1))\n",
        "\n",
        "# Reshape the data for LSTM input\n",
        "X_test_standardized_reshaped = X_test_standardized.reshape((X_test_standardized.shape[0], X_test_standardized.shape[1], 1))\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(X_test_standardized_reshaped)\n",
        "\n",
        "# Inverse transform the predictions to the original scale\n",
        "predictions_original_scale = scaler_y.inverse_transform(predictions)\n",
        "\n",
        "# Ensure that the predicted probabilities sum to 1 for each row\n",
        "predictions_softmax = tf.nn.softmax(tf.convert_to_tensor(predictions_original_scale), axis=-1)\n",
        "\n",
        "# Display or save the predictions as needed\n",
        "submission_df = pd.DataFrame({\n",
        "    'eeg_id': df_test['eeg_id'],\n",
        "    'seizure_vote': predictions_softmax[:, 0],\n",
        "    'lpd_vote': predictions_softmax[:, 1],\n",
        "    'gpd_vote': predictions_softmax[:, 2],\n",
        "    'lrda_vote': predictions_softmax[:, 3],\n",
        "    'grda_vote': predictions_softmax[:, 4],\n",
        "    'other_vote': predictions_softmax[:, 5]\n",
        "})\n",
        "\n",
        "# Ensure the predicted probabilities sum to 1 for each row\n",
        "predictions_sum = np.sum(predictions_softmax, axis=1)\n",
        "assert np.allclose(predictions_sum, 1.0, atol=1e-5), \"Predicted probabilities do not sum to 1 for each row\"\n",
        "\n",
        "# Save the submission DataFrame as a CSV file\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sl571sNvO1f",
        "outputId": "e3c46bc3-59c2-47e3-bf04-fdf9a6b556e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3338/3338 [==============================] - 21s 6ms/step - loss: 1.7787 - accuracy: 0.2094\n",
            "Epoch 2/10\n",
            "3338/3338 [==============================] - 21s 6ms/step - loss: 1.7780 - accuracy: 0.2099\n",
            "Epoch 3/10\n",
            "3338/3338 [==============================] - 18s 5ms/step - loss: 1.7775 - accuracy: 0.2108\n",
            "Epoch 4/10\n",
            "3338/3338 [==============================] - 17s 5ms/step - loss: 1.7773 - accuracy: 0.2104\n",
            "Epoch 5/10\n",
            "3338/3338 [==============================] - 19s 6ms/step - loss: 1.7768 - accuracy: 0.2126\n",
            "Epoch 6/10\n",
            "3338/3338 [==============================] - 17s 5ms/step - loss: 1.7763 - accuracy: 0.2133\n",
            "Epoch 7/10\n",
            "3338/3338 [==============================] - 17s 5ms/step - loss: 1.7758 - accuracy: 0.2141\n",
            "Epoch 8/10\n",
            "3338/3338 [==============================] - 18s 6ms/step - loss: 1.7751 - accuracy: 0.2148\n",
            "Epoch 9/10\n",
            "3338/3338 [==============================] - 18s 5ms/step - loss: 1.7743 - accuracy: 0.2161\n",
            "Epoch 10/10\n",
            "3338/3338 [==============================] - 17s 5ms/step - loss: 1.7734 - accuracy: 0.2152\n",
            "1/1 [==============================] - 0s 428ms/step\n"
          ]
        }
      ]
    }
  ]
}